{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "939bfb8a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "939bfb8a",
    "outputId": "f57b0558-c66e-4418-f2dd-3f154c2a8aab",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m MinMaxScaler, LabelEncoder, PolynomialFeatures\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, PolynomialFeatures\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, recall_score, accuracy_score, classification_report, r2_score as r2\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import torch\n",
    "import keras\n",
    "from keras.constraints import max_norm as MaxNorm\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.ensemble import StackingClassifier, StackingRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['figure.figsize'] = (11.0, 8.0)\n",
    "\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95cd3b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "a95cd3b8",
    "outputId": "04c2636b-fbb1-4eb2-8f61-b596147f865e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing Data\n",
    "df = pd.read_csv('../Data/address_data_combined_ts.csv')\n",
    "X = df.drop(columns=['Address', 'FLAG','Unnamed: 0'])\n",
    "y = df['FLAG']\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "columns = ['Avg min between sent tnx', 'Avg min between received tnx',\n",
    "       'Time Diff between first and last (Mins)',\n",
    "       'Unique Received From Addresses', 'min value received',\n",
    "       'max value received ', 'avg val received', 'min val sent',\n",
    "       'avg val sent', 'total transactions (including tnx to create contract',\n",
    "       'total ether received', 'total ether balance','adjusted_eth_value__absolute_sum_of_changes',\n",
    "     'adjusted_eth_value__mean_abs_change',\n",
    "     'adjusted_eth_value__energy_ratio_by_chunks__num_segments_10__segment_focus_0',\n",
    "     'adjusted_eth_value__sum_values',\n",
    "     'adjusted_eth_value__abs_energy',\n",
    "     'adjusted_eth_value__ratio_value_number_to_time_series_length',\n",
    "     'adjusted_eth_value__quantile__q_0.1',\n",
    "     'adjusted_eth_value__count_below__t_0',\n",
    "     'adjusted_eth_value__count_above__t_0',\n",
    "     'adjusted_eth_value__median']\n",
    "    \n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Log for Skewed Data\n",
    "for c in columns:\n",
    "    X_train_full[c] = X_train_full[c].apply(lambda x: np.log(x) if x > 0 else 0)\n",
    "    X_test[c] = X_test[c].apply(lambda x: np.log(x) if x > 0 else 0)\n",
    "\n",
    "# Scaling\n",
    "X_train_full = scaler.fit_transform(X_train_full)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "np.isnan(X_train_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tV_SwUsUwSxo",
   "metadata": {
    "id": "tV_SwUsUwSxo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train_Xgb, X_test_Xgb, y_train_Xgb, y_Xgb = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c286bb2",
   "metadata": {
    "id": "2c286bb2",
    "outputId": "2bcbf176-efb5-40e9-bc09-050732fb082e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9744, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg min between sent tnx</th>\n",
       "      <th>Avg min between received tnx</th>\n",
       "      <th>Time Diff between first and last (Mins)</th>\n",
       "      <th>Unique Received From Addresses</th>\n",
       "      <th>min value received</th>\n",
       "      <th>max value received</th>\n",
       "      <th>avg val received</th>\n",
       "      <th>min val sent</th>\n",
       "      <th>avg val sent</th>\n",
       "      <th>total transactions (including tnx to create contract</th>\n",
       "      <th>...</th>\n",
       "      <th>adjusted_eth_value__absolute_sum_of_changes</th>\n",
       "      <th>adjusted_eth_value__mean_abs_change</th>\n",
       "      <th>adjusted_eth_value__energy_ratio_by_chunks__num_segments_10__segment_focus_0</th>\n",
       "      <th>adjusted_eth_value__sum_values</th>\n",
       "      <th>adjusted_eth_value__abs_energy</th>\n",
       "      <th>adjusted_eth_value__ratio_value_number_to_time_series_length</th>\n",
       "      <th>adjusted_eth_value__quantile__q_0.1</th>\n",
       "      <th>adjusted_eth_value__count_below__t_0</th>\n",
       "      <th>adjusted_eth_value__count_above__t_0</th>\n",
       "      <th>adjusted_eth_value__median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13918</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999861</td>\n",
       "      <td>0.999861</td>\n",
       "      <td>0.500139</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.499861</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.399875</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5687</th>\n",
       "      <td>159.65</td>\n",
       "      <td>0.5</td>\n",
       "      <td>320.30</td>\n",
       "      <td>2</td>\n",
       "      <td>8.664005</td>\n",
       "      <td>92.335995</td>\n",
       "      <td>50.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>50.499508</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>186.335011</td>\n",
       "      <td>62.111670</td>\n",
       "      <td>0.487592</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>17485.815895</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-67.899311</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.832003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>364.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.259262</td>\n",
       "      <td>0.259262</td>\n",
       "      <td>0.259262</td>\n",
       "      <td>0.258642</td>\n",
       "      <td>0.258642</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517904</td>\n",
       "      <td>0.517904</td>\n",
       "      <td>0.501197</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.134113</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.206852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Avg min between sent tnx  Avg min between received tnx  \\\n",
       "906                        0.00                           0.0   \n",
       "13918                      0.00                           0.0   \n",
       "5687                     159.65                           0.5   \n",
       "914                        0.00                           0.0   \n",
       "7100                       0.00                           0.0   \n",
       "\n",
       "       Time Diff between first and last (Mins)  \\\n",
       "906                                       0.00   \n",
       "13918                                     0.00   \n",
       "5687                                    320.30   \n",
       "914                                       0.00   \n",
       "7100                                    364.87   \n",
       "\n",
       "       Unique Received From Addresses  min value received  \\\n",
       "906                                 0            0.000000   \n",
       "13918                               1            0.500000   \n",
       "5687                                2            8.664005   \n",
       "914                                 0            0.000000   \n",
       "7100                                1            0.259262   \n",
       "\n",
       "       max value received   avg val received  min val sent  avg val sent  \\\n",
       "906               0.000000          0.000000      0.000000      0.000000   \n",
       "13918             0.500000          0.500000      0.000000      0.000000   \n",
       "5687             92.335995         50.500000      7.000000     50.499508   \n",
       "914               0.000000          0.000000      0.000000      0.000000   \n",
       "7100              0.259262          0.259262      0.258642      0.258642   \n",
       "\n",
       "       total transactions (including tnx to create contract  ...  \\\n",
       "906                                                    0     ...   \n",
       "13918                                                  1     ...   \n",
       "5687                                                   4     ...   \n",
       "914                                                    0     ...   \n",
       "7100                                                   2     ...   \n",
       "\n",
       "       adjusted_eth_value__absolute_sum_of_changes  \\\n",
       "906                                       0.000000   \n",
       "13918                                     0.999861   \n",
       "5687                                    186.335011   \n",
       "914                                       0.000000   \n",
       "7100                                      0.517904   \n",
       "\n",
       "       adjusted_eth_value__mean_abs_change  \\\n",
       "906                               0.000000   \n",
       "13918                             0.999861   \n",
       "5687                             62.111670   \n",
       "914                               0.000000   \n",
       "7100                              0.517904   \n",
       "\n",
       "       adjusted_eth_value__energy_ratio_by_chunks__num_segments_10__segment_focus_0  \\\n",
       "906                                             0.000000                              \n",
       "13918                                           0.500139                              \n",
       "5687                                            0.487592                              \n",
       "914                                             0.000000                              \n",
       "7100                                            0.501197                              \n",
       "\n",
       "       adjusted_eth_value__sum_values  adjusted_eth_value__abs_energy  \\\n",
       "906                          0.000000                        0.000000   \n",
       "13918                        0.000139                        0.499861   \n",
       "5687                         0.000984                    17485.815895   \n",
       "914                          0.000000                        0.000000   \n",
       "7100                         0.000620                        0.134113   \n",
       "\n",
       "       adjusted_eth_value__ratio_value_number_to_time_series_length  \\\n",
       "906                                                  0.0              \n",
       "13918                                                1.0              \n",
       "5687                                                 1.0              \n",
       "914                                                  0.0              \n",
       "7100                                                 1.0              \n",
       "\n",
       "       adjusted_eth_value__quantile__q_0.1  \\\n",
       "906                               0.000000   \n",
       "13918                            -0.399875   \n",
       "5687                            -67.899311   \n",
       "914                               0.000000   \n",
       "7100                             -0.206852   \n",
       "\n",
       "       adjusted_eth_value__count_below__t_0  \\\n",
       "906                                     0.0   \n",
       "13918                                   0.5   \n",
       "5687                                    0.5   \n",
       "914                                     0.0   \n",
       "7100                                    0.5   \n",
       "\n",
       "       adjusted_eth_value__count_above__t_0  adjusted_eth_value__median  \n",
       "906                                     0.0                    0.000000  \n",
       "13918                                   0.5                    0.000070  \n",
       "5687                                    0.5                    0.832003  \n",
       "914                                     0.0                    0.000000  \n",
       "7100                                    0.5                    0.000310  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "print(X_train_full.shape)\n",
    "X_train_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d93a698",
   "metadata": {
    "id": "8d93a698",
    "outputId": "b5979466-0264-4637-fa49-065b10b22278",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "columns = ['Avg min between sent tnx', 'Avg min between received tnx',\n",
    "       'Time Diff between first and last (Mins)',\n",
    "       'Unique Received From Addresses', 'min value received',\n",
    "       'max value received ', 'avg val received', 'min val sent',\n",
    "       'avg val sent', 'total transactions (including tnx to create contract',\n",
    "       'total ether received', 'total ether balance','adjusted_eth_value__absolute_sum_of_changes',\n",
    "     'adjusted_eth_value__mean_abs_change',\n",
    "     'adjusted_eth_value__energy_ratio_by_chunks__num_segments_10__segment_focus_0',\n",
    "     'adjusted_eth_value__sum_values',\n",
    "     'adjusted_eth_value__abs_energy',\n",
    "     'adjusted_eth_value__ratio_value_number_to_time_series_length',\n",
    "     'adjusted_eth_value__quantile__q_0.1',\n",
    "     'adjusted_eth_value__count_below__t_0',\n",
    "     'adjusted_eth_value__count_above__t_0',\n",
    "     'adjusted_eth_value__median']\n",
    "    \n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Log for Skewed Data\n",
    "# log on both train and test data\n",
    "for c in columns:\n",
    "    X_train_full[c] = X_train_full[c].apply(lambda x: np.log(x) if x > 0 else 0)\n",
    "    X_test[c] = X_test[c].apply(lambda x: np.log(x) if x > 0 else 0)\n",
    "\n",
    "# Scaling\n",
    "# only use training data to fit, to avoid data leakage\n",
    "X_train_full = scaler.fit_transform(X_train_full)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "np.isnan(X_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb509ec",
   "metadata": {
    "id": "3bb509ec",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Optimal Parameters for each model from hyperparameter tuning\n",
    "tabnet_params = {'gamma': 1.0, \n",
    "                 'lambda_sparse': 0, \n",
    "                 'momentum': 0.4, \n",
    "                 'n_steps': 8, \n",
    "                 'optimizer_params': {'lr': 0.025}, \n",
    "                 'verbose': 0}\n",
    "\n",
    "xgb_params = {'learning_rate': 0.05, \n",
    "              'max_depth': 8, \n",
    "              'n_estimators': 1000}\n",
    "\n",
    "\n",
    "mlp_params = {'input_dim': X_train_full.shape[1],\n",
    "              'H': 60,\n",
    "              'activation': 'relu',\n",
    "              'dropout_probability': 0.2,\n",
    "              'num_epochs': 75,\n",
    "              'num_layers': 10}\n",
    "\n",
    "svm_params = {'C': 1000, \n",
    "              'gamma': 1}\n",
    "\n",
    "rf_params = {'max_depth': 20, \n",
    "               'min_samples_leaf': 5,\n",
    "               'n_jobs': -1}\n",
    "\n",
    "lightgbm_params = {\"bagging_fraction\": 0.95, \n",
    "                   \"bagging_freq\": 1,\n",
    "                   \"feature_fraction\": 0.95,\n",
    "                   \"learning_rate\": 0.2,\n",
    "                   \"max_bin\": 300, \n",
    "                   \"max_depth\": 6,\n",
    "                   \"min_gain_to_split\": 0,\n",
    "                   \"num_leaves\": 20}\n",
    "\n",
    "\n",
    "def compile_mlp(input_dim, H, num_epochs, num_layers, activation, dropout_probability):\n",
    "    # Creating Sequential MLP\n",
    "    model_n = Sequential()\n",
    "    model_n.add(layers.Dense(H, input_shape=(input_dim, ), activation= activation))\n",
    "\n",
    "    for _ in range(num_layers - 1):\n",
    "        model_n.add(layers.Dense(H, activation= activation, kernel_constraint=MaxNorm(3)))\n",
    "        model_n.add(layers.Dropout(dropout_probability))\n",
    "\n",
    "    model_n.add(layers.Dense(1, activation='sigmoid'))\n",
    "    # configure the model\n",
    "    model_n.compile(loss='binary_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.AUC(from_logits=True)])\n",
    "    return model_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c034817",
   "metadata": {
    "id": "9c034817",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get a list of models to evaluate\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    mlp = KerasClassifier(model = compile_mlp, **mlp_params)\n",
    "    tabnet = TabNetClassifier(**tabnet_params)\n",
    "    models['tabnet'] = tabnet\n",
    "    models['svm'] = svm.SVC(**svm_params)\n",
    "    models['xgboost'] = XGBClassifier(**xgb_params)\n",
    "    models['mlp'] = mlp\n",
    "    models['lightGBM'] = lgb.LGBMClassifier(**lightgbm_params)\n",
    "    models['randomforest'] = RandomForestClassifier(**rf_params)\n",
    "    return models\n",
    " \n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=1, random_state=42)\n",
    "    scores = cross_val_score(model, X, y, scoring='f1', cv=cv, n_jobs=-1)#, error_score='raise')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805bf398",
   "metadata": {
    "id": "805bf398",
    "outputId": "67f540a3-0859-4e0b-88ef-0905f9cbe1db",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">tabnet 0.898 (0.004)\n",
      ">svm 0.918 (0.004)\n",
      ">xgboost 0.929 (0.005)\n",
      ">mlp 0.843 (0.010)\n",
      ">lightGBM 0.928 (0.006)\n",
      ">randomforest 0.911 (0.004)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define dataset\n",
    "X, y = X_train_full, y_train_full\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    if name == 'xgboost':\n",
    "        scores = evaluate_model(model, X_train_Xgb, y_train_Xgb)\n",
    "    else:\n",
    "        scores = evaluate_model(model, X, y)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n",
    "# plot model performance for comparison\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b017856f",
   "metadata": {
    "id": "b017856f",
    "outputId": "12322ef9-efc2-49ab-d6cd-b84e8d4e160f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305/305 [==============================] - 2s 2ms/step - loss: 0.5696 - auc: 0.7767\n",
      "131/131 [==============================] - 0s 646us/step\n",
      "131/131 [==============================] - 0s 746us/step\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "\n",
    "#Creating Stacking model - Initialized using logistic regression model\n",
    "def get_stacking():\n",
    "    # define the base models\n",
    "    level0 = list()\n",
    "    for key,value in get_models().items():\n",
    "        try:\n",
    "            value._estimator_type = 'classifier'\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        finally:\n",
    "            level0.append([key,value])\n",
    "    # define meta learner model\n",
    "    level1 = LogisticRegression()\n",
    "    # define the stacking ensemble\n",
    "    model = StackingClassifier(estimators=level0, final_estimator=level1, cv= 5, n_jobs = -1)\n",
    "    return model\n",
    "\n",
    "#Pipeline to get all models\n",
    "def get_models2():\n",
    "    models = dict()\n",
    "    models['tabnet'] = TabNetClassifier(**tabnet_params)\n",
    "    models['svm'] = svm.SVC(**svm_params)\n",
    "    models['xgboost'] = XGBClassifier(**xgb_params)\n",
    "    models['mlp'] = KerasClassifier(model = compile_mlp, **mlp_params)\n",
    "    models['lightGBM'] = lgb.LGBMClassifier()\n",
    "    models['stacking'] = get_stacking()\n",
    "    return models\n",
    "\n",
    "#Getting predictions from all models to evaluate performance on test set\n",
    "predictions, names2, timing_list = list(), list(), list()\n",
    "for name, model in get_models2().items():\n",
    "    current_time = time.time()\n",
    "    if name == 'xgboost':\n",
    "        model.fit(X_train_Xgb, y_train_Xgb)\n",
    "        predictions.append(model.predict(X_test_Xgb))\n",
    "    else:\n",
    "        model.fit(X, y)\n",
    "        predictions.append(model.predict(X_test))\n",
    "    names2.append(name)\n",
    "    final_time = time.time()\n",
    "    timing_list.append(final_time - current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e090999a",
   "metadata": {
    "id": "e090999a",
    "outputId": "9571ae11-d111-4f5f-f2b8-a745b06f5b88",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Time taken</th>\n",
       "      <th>Optimal Parameters</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>7.739865</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 8, 'n_est...</td>\n",
       "      <td>0.938937</td>\n",
       "      <td>0.933511</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.932271</td>\n",
       "      <td>0.938237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>stacking</td>\n",
       "      <td>311.956367</td>\n",
       "      <td>None</td>\n",
       "      <td>0.938697</td>\n",
       "      <td>0.929815</td>\n",
       "      <td>0.934748</td>\n",
       "      <td>0.932275</td>\n",
       "      <td>0.938347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lightGBM</td>\n",
       "      <td>0.122057</td>\n",
       "      <td>{'bagging_fraction': 0.95, 'bagging_freq': 1, ...</td>\n",
       "      <td>0.937979</td>\n",
       "      <td>0.930159</td>\n",
       "      <td>0.932626</td>\n",
       "      <td>0.931391</td>\n",
       "      <td>0.937505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svm</td>\n",
       "      <td>5.429924</td>\n",
       "      <td>{'C': 1000, 'gamma': 1}</td>\n",
       "      <td>0.928400</td>\n",
       "      <td>0.919577</td>\n",
       "      <td>0.922016</td>\n",
       "      <td>0.920795</td>\n",
       "      <td>0.927835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tabnet</td>\n",
       "      <td>89.649050</td>\n",
       "      <td>{'gamma': 1.0, 'lambda_sparse': 0, 'momentum':...</td>\n",
       "      <td>0.910920</td>\n",
       "      <td>0.939570</td>\n",
       "      <td>0.857825</td>\n",
       "      <td>0.896839</td>\n",
       "      <td>0.906215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mlp</td>\n",
       "      <td>2.433358</td>\n",
       "      <td>{'input_dim': 22, 'H': 60, 'activation': 'relu...</td>\n",
       "      <td>0.857280</td>\n",
       "      <td>0.866818</td>\n",
       "      <td>0.807958</td>\n",
       "      <td>0.836354</td>\n",
       "      <td>0.852909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Time taken                                 Optimal Parameters  \\\n",
       "2   xgboost    7.739865  {'learning_rate': 0.05, 'max_depth': 8, 'n_est...   \n",
       "5  stacking  311.956367                                               None   \n",
       "4  lightGBM    0.122057  {'bagging_fraction': 0.95, 'bagging_freq': 1, ...   \n",
       "1       svm    5.429924                            {'C': 1000, 'gamma': 1}   \n",
       "0    tabnet   89.649050  {'gamma': 1.0, 'lambda_sparse': 0, 'momentum':...   \n",
       "3       mlp    2.433358  {'input_dim': 22, 'H': 60, 'activation': 'relu...   \n",
       "\n",
       "   Accuracy  Precision    Recall        F1   ROC-AUC  \n",
       "2  0.938937   0.933511  0.931034  0.932271  0.938237  \n",
       "5  0.938697   0.929815  0.934748  0.932275  0.938347  \n",
       "4  0.937979   0.930159  0.932626  0.931391  0.937505  \n",
       "1  0.928400   0.919577  0.922016  0.920795  0.927835  \n",
       "0  0.910920   0.939570  0.857825  0.896839  0.906215  \n",
       "3  0.857280   0.866818  0.807958  0.836354  0.852909  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, recall_score, accuracy_score, precision_score\n",
    "results_df = pd.DataFrame()\n",
    "results_df['Model'] = names2\n",
    "results_df['Time taken'] = timing_list\n",
    "results_df['Optimal Parameters'] = [tabnet_params,\n",
    "                                    svm_params,\n",
    "                                    xgb_params,\n",
    "                                    mlp_params,\n",
    "                                    lightgbm_params,\n",
    "                                    None]\n",
    "metrics_dict = {'Accuracy': accuracy_score, \n",
    "                'Precision': precision_score, \n",
    "                'Recall': recall_score, \n",
    "                'F1': f1_score, \n",
    "                'ROC-AUC': roc_auc_score}\n",
    "for metric, func in metrics_dict.items():\n",
    "    storage = []\n",
    "    for prediction in predictions:\n",
    "        storage.append(func(y_test, prediction))\n",
    "    results_df[metric] = storage\n",
    "\n",
    "results_df.sort_values(['Accuracy', 'ROC-AUC'], ascending = [False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec68df3",
   "metadata": {
    "id": "8ec68df3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
